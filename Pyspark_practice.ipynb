{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZC86u6aPfZyWmoLO8DhXc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yashwanth-1406/classicmodels-spark-analytics/blob/main/Pyspark_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2JXHeROP13X",
        "outputId": "a5249511-91cb-4935-a8f8-d8504730053c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark is ready 3.5.1\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName(\"Dataframe\").getOrCreate()\n",
        "print(\"Spark is ready\",spark.version)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "s1=SparkSession.builder.appName(\"yp\").getOrCreate()\n",
        "data=[(\"yp\",21),(\"kp\",22),(\"sp\",23)]\n",
        "df=s1.createDataFrame(data,[\"Name\",\"age\"])\n",
        "df.show()\n",
        "print(s1.version)\n",
        "df.select(\"Name\").show()\n",
        "\n",
        "df.filter(df.age==22).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBJwiYXHRh9q",
        "outputId": "ebc5bd9d-475e-4f9c-ba6e-d9ab0fcc31a4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+\n",
            "|Name|age|\n",
            "+----+---+\n",
            "|  yp| 21|\n",
            "|  kp| 22|\n",
            "|  sp| 23|\n",
            "+----+---+\n",
            "\n",
            "3.5.1\n",
            "+----+\n",
            "|Name|\n",
            "+----+\n",
            "|  yp|\n",
            "|  kp|\n",
            "|  sp|\n",
            "+----+\n",
            "\n",
            "+----+---+\n",
            "|Name|age|\n",
            "+----+---+\n",
            "|  kp| 22|\n",
            "+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "df1=df.withColumn(\"Ageafter5years\",col(\"age\")+5)\n",
        "df1.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQgnJVu5RiAY",
        "outputId": "cd36cda0-02fa-4a01-cd0a-89087df6d381"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+--------------+\n",
            "|Name|age|Ageafter5years|\n",
            "+----+---+--------------+\n",
            "|  yp| 21|            26|\n",
            "|  kp| 22|            27|\n",
            "|  sp| 23|            28|\n",
            "+----+---+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import lit\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "schema=StructType([\n",
        "    StructField(\"Name\",StringType(),True),\n",
        "    StructField(\"Age\",IntegerType(),True)\n",
        "])\n",
        "\n",
        "df=s1.createDataFrame([],schema)\n",
        "df.show()\n",
        "df2=df.withColumn(\"lname\",lit(None))\n",
        "df2.show()\n",
        "df3=df2.withColumn(\"hi\",when(col(\"age\")>=18,\"yes\").otherwise(\"No\"))\n",
        "df3.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZfyogpxaJGb",
        "outputId": "4639aaef-f0c5-43ba-f359-3668cb888613"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+\n",
            "|Name|Age|\n",
            "+----+---+\n",
            "+----+---+\n",
            "\n",
            "+----+---+-----+\n",
            "|Name|Age|lname|\n",
            "+----+---+-----+\n",
            "+----+---+-----+\n",
            "\n",
            "+----+---+-----+---+\n",
            "|Name|Age|lname| hi|\n",
            "+----+---+-----+---+\n",
            "+----+---+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wwQ2NsViTXx9"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "s2=SparkSession.builder.appName(\"app1\").getOrCreate()\n",
        "d1=[(\"Alice\",22),(\"Bob\",22),(\"yash\",23)]\n",
        "df3=s2.createDataFrame(d1,[\"Name\",\"Age\"])\n",
        "df3.show()\n",
        "df4=df3.withColumnRenamed(\"Name\",\"FullName\")\n",
        "df4.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzjcklYDRiDw",
        "outputId": "ea20efab-f04d-4ccd-ba55-a465e15e2c5f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| Name|Age|\n",
            "+-----+---+\n",
            "|Alice| 22|\n",
            "|  Bob| 22|\n",
            "| yash| 23|\n",
            "+-----+---+\n",
            "\n",
            "+--------+---+\n",
            "|FullName|Age|\n",
            "+--------+---+\n",
            "|   Alice| 22|\n",
            "|     Bob| 22|\n",
            "|    yash| 23|\n",
            "+--------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName(\"yp\").getOrCreate()\n",
        "data=[(\"yp\",22,\"it\"),(\"sp\",23,\"it\"),(\"kp\",23,\"it\")]\n",
        "df=spark.createDataFrame(data,[\"Name\",\"age\",\"dept\"])\n",
        "df.show()\n",
        "df.show(2)\n",
        "df1=df.collect()\n",
        "for row in df1:\n",
        "  print(row)\n",
        "\n",
        "df.count()\n",
        "\n",
        "\n",
        "df.first()\n",
        "\n",
        "df.take(2)\n",
        "df.head(1)\n",
        "pdf=df.toPandas()\n",
        "print(pdf)\n",
        "\n",
        "df.write.csv(\"yp.csv\",header=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "PZO9xKiQTYqe",
        "outputId": "f4fec3b1-a8a3-49e1-e308-6ac50dd8fc59"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+----+\n",
            "|Name|age|dept|\n",
            "+----+---+----+\n",
            "|  yp| 22|  it|\n",
            "|  sp| 23|  it|\n",
            "|  kp| 23|  it|\n",
            "+----+---+----+\n",
            "\n",
            "+----+---+----+\n",
            "|Name|age|dept|\n",
            "+----+---+----+\n",
            "|  yp| 22|  it|\n",
            "|  sp| 23|  it|\n",
            "+----+---+----+\n",
            "only showing top 2 rows\n",
            "\n",
            "Row(Name='yp', age=22, dept='it')\n",
            "Row(Name='sp', age=23, dept='it')\n",
            "Row(Name='kp', age=23, dept='it')\n",
            "  Name  age dept\n",
            "0   yp   22   it\n",
            "1   sp   23   it\n",
            "2   kp   23   it\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[PATH_ALREADY_EXISTS] Path file:/content/yp.csv already exists. Set mode as \"overwrite\" to overwrite the existing path.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3928050577.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yp.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mlineSep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineSep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m         )\n\u001b[0;32m-> 1864\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m     def orc(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [PATH_ALREADY_EXISTS] Path file:/content/yp.csv already exists. Set mode as \"overwrite\" to overwrite the existing path."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def even_or_odd(num):\n",
        "  if num%2==0:\n",
        "    print(\"even\")\n",
        "  else:\n",
        "    print(\"odd\")\n",
        "\n",
        "even_or_odd(24)"
      ],
      "metadata": {
        "id": "lkCwt0CdTY7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add(a,b):\n",
        "  c=a+b\n",
        "  return a\n",
        "add(2,2)"
      ],
      "metadata": {
        "id": "E-7p5EqHTZA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name=\"yashu\"):\n",
        "  print(f\"Hello {name}\")\n",
        "\n",
        "greet()\n",
        "greet(\"sp\")"
      ],
      "metadata": {
        "id": "VqR5bT8fTZDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Variable length arguements\n",
        "# 1. positional and keywords arguements\n",
        "\n",
        "def print_numbers(*args):\n",
        "  for numbers in args:\n",
        "    print(numbers)\n",
        "\n",
        "print_numbers(1,2,3,4,5,6,7,8)\n"
      ],
      "metadata": {
        "id": "SmRW3cAkTZFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_details(**kwargs):\n",
        "  for key,value in kwargs.items():\n",
        "    print(f\"{key}:{value}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "rR1_Lqp4bvEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_details(name=\"yashu\",age=\"32\",country=\"india\")"
      ],
      "metadata": {
        "id": "FGZT63_TTZHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VqLvLP0hTZK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName(\"Transformations\").getOrCreate()\n",
        "data=[(\"YP\",21),(\"Sp\",22),(\"Kp\",23)]\n",
        "df=spark.createDataFrame(data,[\"Name\",\"Age\"])\n",
        "df.show()\n",
        "df2=df.select(\"Name\")\n",
        "df2.show()\n",
        "df3=df.filter(df.Age==21)\n",
        "df3.show()\n",
        "df.count()\n",
        "rows=df.collect()\n",
        "for row in rows:\n",
        "  print(row)\n"
      ],
      "metadata": {
        "id": "UxlCBsfLlaxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yashu(*args,**kwargs):\n",
        "  for val in args:\n",
        "    print(f\"positional arguements {val}\")\n",
        "\n",
        "  for key,value in kwargs.items():\n",
        "    print(f\"keyword arguements {key}:{value}\")\n",
        "\n",
        "yashu(1,2,3,4,5,name=\"yp\",dept=\"sp\")"
      ],
      "metadata": {
        "id": "lQs4ZX8CgDUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Lambda function\n",
        "\n",
        "add=lambda a,b:a+b\n",
        "print(add(2,3))"
      ],
      "metadata": {
        "id": "ZFgC7AvHgDYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def addition(x,y,z):\n",
        "  return x,y,z\n",
        "addition(2,3,4)"
      ],
      "metadata": {
        "id": "bTenv1YqgDfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf1a89b8-05af-4166-9afe-b44d99544ee3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 3, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add=lambda x,y,z:x+y+z\n",
        "print(add(2,7,8))"
      ],
      "metadata": {
        "id": "Vkz5NwysgDiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84793145-eb88-4cab-ded7-1fad4c881525"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numbers=[1,2,3,4,5]\n",
        "list(map(lambda x:x**2,numbers))"
      ],
      "metadata": {
        "id": "FXg3v50wgDkp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8261cfe2-9cf7-4d9b-8880-7ea4185c65fa"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 4, 9, 16, 25]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num1=[1,2,3,4,5]\n",
        "num2=[4,5,6,7,8]\n",
        "add=list(map(lambda x,y:x+y,num1,num2))\n",
        "print(add)"
      ],
      "metadata": {
        "id": "ry3uGZ-TgDm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13907c0c-b792-474b-e604-ff1b6e1e9df7"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 7, 9, 11, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str_number=['1','2','3','4','5']\n",
        "int_numbers=list(map(int,str_number))\n",
        "print(int_numbers)"
      ],
      "metadata": {
        "id": "o4w_fKbVgDpK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf3d052-a205-4cc5-d3da-e27ebb6fdaf8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words=['apple','banana','cherry']\n",
        "upper_word=list(map(str.upper,words))\n",
        "print(upper_word)"
      ],
      "metadata": {
        "id": "FuyXNbDEgDrf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef6e4d5-7904-4f20-85f8-aa5116217187"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['APPLE', 'BANANA', 'CHERRY']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from builtins import filter\n",
        "\n",
        "def even(num):\n",
        "    return num % 2 == 0\n",
        "\n",
        "num = [1,2,3,4,5,6,7,8,9,10]\n",
        "print(list(filter(even, num)))\n"
      ],
      "metadata": {
        "id": "ccsv471JgDth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b64f57a-7a28-4425-a583-47569cb2f8a1"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 4, 6, 8, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode\n",
        "\n",
        "data = [(\"Alice\", [\"Python\", \"Java\"]), (\"Bob\", [\"C++\", \"Go\"])]\n",
        "df = spark.createDataFrame(data, [\"Name\", \"Skills\"])\n",
        "\n",
        "df2 = df.withColumn(\"Skill\", explode(df.Skills))\n",
        "df2.show()\n",
        "df1=df2.withColumnRenamed(\"Name\",\"Fname\")\n",
        "df1.show()\n",
        "df3=df1.dropDuplicates([\"Skills\"])\n",
        "df3.show()\n",
        "df4.repartition(2)\n",
        "df4.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUTpeBleutVD",
        "outputId": "54593cee-0c8e-493f-973d-05b55cfffa4a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------+------+\n",
            "| Name|        Skills| Skill|\n",
            "+-----+--------------+------+\n",
            "|Alice|[Python, Java]|Python|\n",
            "|Alice|[Python, Java]|  Java|\n",
            "|  Bob|     [C++, Go]|   C++|\n",
            "|  Bob|     [C++, Go]|    Go|\n",
            "+-----+--------------+------+\n",
            "\n",
            "+-----+--------------+------+\n",
            "|Fname|        Skills| Skill|\n",
            "+-----+--------------+------+\n",
            "|Alice|[Python, Java]|Python|\n",
            "|Alice|[Python, Java]|  Java|\n",
            "|  Bob|     [C++, Go]|   C++|\n",
            "|  Bob|     [C++, Go]|    Go|\n",
            "+-----+--------------+------+\n",
            "\n",
            "+-----+--------------+------+\n",
            "|Fname|        Skills| Skill|\n",
            "+-----+--------------+------+\n",
            "|  Bob|     [C++, Go]|   C++|\n",
            "|Alice|[Python, Java]|Python|\n",
            "+-----+--------------+------+\n",
            "\n",
            "+--------+---+\n",
            "|FullName|Age|\n",
            "+--------+---+\n",
            "|   Alice| 22|\n",
            "|     Bob| 22|\n",
            "|    yash| 23|\n",
            "+--------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (\"Alice\", \"HR\", 2500),\n",
        "    (\"Bob\", \"IT\", 3000),\n",
        "    (\"Cathy\", \"Finance\", 4000),\n",
        "    (\"David\", \"IT\", 3500),\n",
        "    (\"Eva\", \"HR\", 2800)\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data, [\"Name\", \"Dept\", \"Salary\"])\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3QH9na5utX-",
        "outputId": "983d1754-c836-4e92-e68a-a4e9f020978c"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+------+\n",
            "| Name|   Dept|Salary|\n",
            "+-----+-------+------+\n",
            "|Alice|     HR|  2500|\n",
            "|  Bob|     IT|  3000|\n",
            "|Cathy|Finance|  4000|\n",
            "|David|     IT|  3500|\n",
            "|  Eva|     HR|  2800|\n",
            "+-----+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum\n",
        "df.groupBy(\"Dept\").agg(sum(\"Salary\").alias(\"TotalSalary\")).show()\n",
        "df.groupBy(\"Dept\").agg(count(\"Salary\").alias(\"TotalSalary\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCmC2U5Iutaz",
        "outputId": "32170162-fd46-4d69-842a-640b4d4297f1"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+\n",
            "|   Dept|TotalSalary|\n",
            "+-------+-----------+\n",
            "|     HR|       5300|\n",
            "|     IT|       6500|\n",
            "|Finance|       4000|\n",
            "+-------+-----------+\n",
            "\n",
            "+-------+-----------+\n",
            "|   Dept|TotalSalary|\n",
            "+-------+-----------+\n",
            "|     HR|          2|\n",
            "|     IT|          2|\n",
            "|Finance|          1|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg, max\n",
        "df.groupBy(\"Dept\").agg(\n",
        "    avg(\"Salary\").alias(\"Emp_Salary\"),\n",
        "    max(\"Salary\").alias(\"Emp_higher Sal\")).show()\n",
        "\n",
        "df.groupBy(\"Dept\",\"Name\").agg(sum(\"Salary\").alias(\"Total\")).show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mONuY8Tautdr",
        "outputId": "11930628-2254-40ff-9530-e33e023cd43f"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+--------------+\n",
            "|   Dept|Emp_Salary|Emp_higher Sal|\n",
            "+-------+----------+--------------+\n",
            "|     HR|    2650.0|          2800|\n",
            "|     IT|    3250.0|          3500|\n",
            "|Finance|    4000.0|          4000|\n",
            "+-------+----------+--------------+\n",
            "\n",
            "+-------+-----+-----+\n",
            "|   Dept| Name|Total|\n",
            "+-------+-----+-----+\n",
            "|     IT|  Bob| 3000|\n",
            "|     HR|Alice| 2500|\n",
            "|Finance|Cathy| 4000|\n",
            "|     IT|David| 3500|\n",
            "|     HR|  Eva| 2800|\n",
            "+-------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank\n",
        "\n",
        "windowSpec = Window.partitionBy(\"Dept\").orderBy(df[\"Salary\"].desc())\n",
        "\n",
        "df.withColumn(\"Rank\", rank().over(windowSpec)).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTQ1b0zfutgT",
        "outputId": "baa7581f-e2db-49d8-ae86-e0fa19ba78d3"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+------+----+\n",
            "| Name|   Dept|Salary|Rank|\n",
            "+-----+-------+------+----+\n",
            "|Cathy|Finance|  4000|   1|\n",
            "|  Eva|     HR|  2800|   1|\n",
            "|Alice|     HR|  2500|   2|\n",
            "|David|     IT|  3500|   1|\n",
            "|  Bob|     IT|  3000|   2|\n",
            "+-----+-------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NyKJSVp6uti5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bw6GOG9Kutlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "llFedGs8utpK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}